{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlWLe0-PeAHs"
   },
   "source": [
    "# Assignment 2: Statistical Learning & Sound Event Classification Fundamentals\n",
    "\n",
    "CS-GY 9223: Machine Listening\n",
    "\n",
    "Below you will find a mix of coding questions and writing questions to familiarize you with the fundamentals of signal processing in Python.\n",
    "\n",
    "**Read through the text, code, and comments carefully and fill-in the blanks accordingly. Written questions will be denoted with‚ùì, and code questions will be explained in code comments, both with \"TODO\" markers. Code fill-ins will also often have templated \"Nones\" where you'll fill in that part.**\n",
    "\n",
    "**For all plots, include axis labels with units of measurement when applicable. Lack of this will result in small points deductions.**\n",
    "\n",
    "The assignment will be 10 points total (possibility of +2 points extra credit). Each code and text question is labeled with fractional point values.\n",
    "\n",
    "### ‚ö†Ô∏è Before you begin - Python packages‚ö†Ô∏è\n",
    "For this assignment you will need Pandas (`pip install pandas`), tqdm (`pip install tqdm`), scikit-learn, and librosa in addition to matplotlib and numpy (which you should have from the first assignment). If you don't have all of these already in your environment/Conda environment, open your terminal, activate your Conda environment, and `pip install <package>` from there *before* launching `jupyter notebook` from within that environment. Then, when you launch the notebook and go to select your kernel, that environment will now have those packages installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udNrQcDf0g0s",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Part 1: Warming up machine learning fundamentals [2 pts]\n",
    "\n",
    "In this section you will use a simple dataset to experiment with data splitting and pre-processing and machine learning model selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ap89uAlf1tK-"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import IPython "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSOGYBcVDeeN"
   },
   "source": [
    "### 1.1 Loading data and basic manipulations üêß [0.5 pts]\n",
    "Download the awesome **penguins** dataset from this link: https://github.com/mwaskom/seaborn-data/blob/71e2436a092d714350de0fc409ca8a8714e7e78f/penguins.csv as a CSV file.\n",
    "\n",
    "The dataset consists of 7 columns:\n",
    "\n",
    "* `species`: penguin species (Chinstrap, Ad√©lie, or Gentoo)\n",
    "* `island`: island name (Dream, Torgersen, or Biscoe) in the Palmer Archipelago (Antarctica)\n",
    "* `bill_length_mm`: bill length (mm)\n",
    "* `bill_depth_mm`: bill depth (mm)\n",
    "* `flipper_length_mm`: flipper length (mm)\n",
    "* `body_mass_g`: flipper length (mm)\n",
    "* `sex`: penguin sex\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fadCiDbBGaEc",
    "outputId": "4e2cc859-73f0-4e57-8b75-bd136bc41914"
   },
   "outputs": [],
   "source": [
    "# TODO : Load the dataset into a Pandas DataFrame [0.1 pt]\n",
    "# TODO : Print the first 5 rows of the dataset using df.head()\n",
    "df = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzLuJRzENXIC",
    "outputId": "767adbf0-f002-40d1-d73b-8638a72cebaa"
   },
   "outputs": [],
   "source": [
    "# TODO : Filter out rows that have any NaN values. [0.05 pt]\n",
    "# TODO : Print the number of samples in the dataset before and after filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "5S1sGDl4P1Lf",
    "outputId": "805bff22-87d2-4d27-99b6-87e6d2d9e5c2"
   },
   "outputs": [],
   "source": [
    "# TODO : Print the number of samples per species [0.05 pt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "vOr8ajVxN9kY",
    "outputId": "ffb84080-fca3-4249-ca08-1f0004b7dc42"
   },
   "outputs": [],
   "source": [
    "# TODO : Create a DataFrame of the mean flipper length by species and sex within each species and display it [0.1 pt]\n",
    "df_mean = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "mjMhr0TrPETn",
    "outputId": "33c1c9e0-d6d9-4043-d78e-adb76c6ede95"
   },
   "outputs": [],
   "source": [
    "# TODO : Add a column to the original DataFrame that maps the 3 species types to the labels [0,1,2] [0.1 pt]\n",
    "# Name this column \"species_label\"\n",
    "# TODO : Print the first 5 rows of the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "XGDTd0wKOc1t",
    "outputId": "0b312a6a-3e9e-4e92-9659-e0545f1e16f5"
   },
   "outputs": [],
   "source": [
    "# TODO : Exploratory data plot using matplotlib or seaborn [0.1 pt]\n",
    "# Plot a scatter plot with flipper length on the x-axis, bill-length on the y-axis, colored by species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38vIfp1uRyqr"
   },
   "source": [
    "### 1.2 Data preprocessing and splitting [0.5 pts]\n",
    "You will use flipper length and bill length as your continuous features, and species as your target (but use `species_label`) for training your model. First you will split the data into a training and testing set. After splitting the data, we need to normalize or standardize the data in some way because the scale of data across features differs, use **min-max normalization**, defined as $x' = \\frac{x - min(x)}{max(x) - min(x)}$. Write min-max normalization by hand here, ‚ö†Ô∏è**do not use a built-in function**‚ö†Ô∏è.\n",
    "\n",
    "Calculate the minimum and maximum *per feature* across the training dataset, and then apply this formula to every sample, using those min/max values. **You will also use these normalization values in validation and test!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZHDDeEIU9H7"
   },
   "outputs": [],
   "source": [
    "# TODO : Assign your feature data , which should be a numpy array size (333,2) to `X` [0 pt]\n",
    "# TODO : Assign your target data to `y`, which should be a numpy array shape (333,)\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "\n",
    "# TODO : Split your data into training and test sets using scikit-learn's train_test_split [0.1 pt]\n",
    "# We will use cross validation to internally split the training set into train-val.\n",
    "# Use 80% of your data for train, 20% for test\n",
    "# Hint: pass `stratify=y` to make sure your splits are balanced in terms of species class\n",
    "X_train, X_test, y_train, y_test = (None, None, None, None)\n",
    "\n",
    "# TODO : Use the training data statistics to min-max normalize each feature [0.4 pts]\n",
    "# First calculate the statistics per feature on the training set\n",
    "# Important! Normalize the test features by the statistics from the training set\n",
    "\n",
    "min_flipper, min_bill = (None, None)\n",
    "max_flipper, max_bill = (None, None)\n",
    "\n",
    "# TODO : Use these stats to normalize the features         \n",
    "flipper_norm_train = None\n",
    "bill_norm_train = None\n",
    "flipper_norm_test = None\n",
    "bill_norm_test = None\n",
    "\n",
    "# and bring them back together\n",
    "X_train_norm = None\n",
    "X_test_norm = None\n",
    "\n",
    "# TODO : Print the shape of your train and test features and targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_jUrh9mTUhE",
    "outputId": "5677c4e7-857a-4db6-bc7f-4bccfb829fff"
   },
   "outputs": [],
   "source": [
    "# TODO : Print the number of samples per class in each of the data splits [0 pt]\n",
    "# Ensure that classes are proportionately balanced across splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9alZ5PzWEZ7"
   },
   "source": [
    "### 1.3 Basic model training and hyperparameter tuning [1 pt]\n",
    "Now you'll be training a model to predict species given your features. \n",
    "You'll be using **[Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)**.\n",
    "You can use the `scikit-learn` implementations of both. The documentation provides helpful info on the parameters that you'll need to tweak for the experiments below.\n",
    "\n",
    "We will be exploring the use of regularization weighting (lambda) **hyperparameter** as discussed in class. \n",
    "To select the best parameter for lambda, use **cross-validation**. Once you've found the best value for lambda, train one final model using those parameters and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R63IUy_JQvk9",
    "outputId": "df60dfd0-304c-4a5b-e48c-d671aaaa3d8a"
   },
   "outputs": [],
   "source": [
    "# TODO : Train a logistic regression model to predict penguin species (using scikit-learn!) [0.75 pts]\n",
    "# TODO : use 5-fold cross validation to find the best combination of regularization type and weight of regularization (lambda)\n",
    "# Use penalty = 'l2'\n",
    "# Print the accuracy of each model\n",
    "\n",
    "lambdas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "penalty = 'l2'\n",
    "\n",
    "# Train your models here \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZEoksZARDBQ",
    "outputId": "10738a07-6148-499a-84a7-76b676113d60"
   },
   "outputs": [],
   "source": [
    "# TODO : evaluate the best performing combinations of both models on the test set [0.25 pts]\n",
    "# Print your test accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_7vrKkf1pxz"
   },
   "source": [
    "# Part 2: Sound Event Classification with ESC-50 [8 pts]\n",
    "\n",
    "Now that you've got a standard machine learning framework under your belt, let's do what you came here for: working with audio and designing *machine listening* systems!\n",
    "\n",
    "You'll be working with a popular environmental sound classification dataset: **[ESC-50](https://github.com/karolpiczak/ESC-50)** for these experiments. We will walk through loading the data and get you more familiar with audio feature extraction and simple model training on real audio data, but with the same principles we used in Part 1.\n",
    "\n",
    "A few notes about the ESC-50 data:\n",
    "- 2000 x 5-second long audio recordings in .wav format, in the `audio/*.wav` folder\n",
    "- original audio has 44.1 kHz sample rate, mono\n",
    "- metadata can be found in `meta/esc50.csv`\n",
    "    - `target` is the target class index, while `category` is the name of that class\n",
    "    - `fold` contains predefined cross-validation folds. For our purposes, we'll use folds 1-3 for training, 4 for val, and 5 for test\n",
    "    - you can ignore the `esc10` and `take` columns for this assignment\n",
    "\n",
    "\n",
    "Begin by **downloading the data**: https://github.com/karolpiczak/ESC-50?tab=readme-ov-file#download (~600mb). For more details on the structure of the data and metadata, see [the repository readme](https://github.com/karolpiczak/ESC-50).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qILaDJyNfPgh"
   },
   "source": [
    "### 2.1 Loading data and preliminary analysis [1 pt code + 0.4pts written = 1.4 pts]\n",
    "We will take a look at the metadata, and do some preliminary feature extraction to better-understand the features we'll use to train our sound event classifier in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l17E1gleV_gk"
   },
   "outputs": [],
   "source": [
    "# TODO : Load the metadata file into a Pandas dataframe and print the first 5 rows [0.05 pts]\n",
    "data_path = None # define your path to ESC-50 directory\n",
    "meta_df = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Load an audio file from the `cow` class using Librosa. Use the native sample rate. [0.05 pts]\n",
    "# TODO : Plot the waveform \n",
    "# TODO : Print the number of audio samples and the sample rate (bonus: plotting x-axis labels with time and not samples :) )\n",
    "# TODO : Play the sample audio above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrogram Exploration [0.9 pts]\n",
    "\n",
    "TODO : Make a plot with 3 subplots: \n",
    "1. linear-frequency power spectrogram\n",
    "2. log-frequency spectrogram\n",
    "3. log-mel frequency spectrogram\n",
    "\n",
    "Use librosa for computing features. You can use vanilla matplotlib `imshow` for plotting, or `librosa.display.specshow`. A few points to clarify: the `y_axis` parameter in `librosa.display.specshow` does **not** actually change the spectrogram data itself (e.g. if you pass \"log\", this is purely for visualization purposes). In fact, I recommend plotting your linear and log spectrograms both with log y-axis labeling for better comparison, so that you can really see the difference in your features - not just as an artifact of visualization. You can also pass `y_axis=mel` to `librosa.display.specshow` for the mel spectrogram plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Follow the instructions above to explore 3 types of spectrograms on your sample audio via plots [0.9 pts, 0.3 pts per feature/plot]\n",
    "# Here are some initial window/hop sizes and n_mels, but in the next question you'll explore different options\n",
    "win_length = 1024\n",
    "hop_length = 1024//2\n",
    "n_mels = 128\n",
    "\n",
    "# TODO : define your spectrograms here\n",
    "lin_power_spec = None\n",
    "log_spec = None\n",
    "mel_spec = None\n",
    "log_mel_spec = None\n",
    "\n",
    "# TODO : define your plots here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì 1. **[QUESTION]**\n",
    "Experiment with a few different combinations of window lengths and hop lengths for the spectrograms above on your sample signal, using what you learned from the last assignment about the trade-offs between these parameters. Land on a combination you observe/hypothesize is best for this type of environmental sound data. Explain your parameter choices and how these choices impact the features you see in the plots. [0.2 pts]\n",
    "\n",
    "**ANSWER:**\n",
    "\n",
    "\n",
    "‚ùì 2. **[QUESTION]** \n",
    "Aside from your window and hop size choices, (1) what do you observe about the differences between the 3 types of spectrograms above (i.e. for one set of parameters)? Write about the differences you see (maybe also experiment with multiple audio files). (2) Which type of spectrogram do you think would be the best to use as features for training a sound event classifier? [0.2 pts]\n",
    "\n",
    "**ANSWER:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.2 Feature Extraction [2pts code + 0.2pts written = 2.2 pts]\n",
    "Next, let's expand this feature extraction such that we can apply it to an entire data split and have a bit more flexibility. Complete the function below following the docstrings, for the three types of features we explored above.\n",
    "\n",
    "Note that for this assignment, we will aggregate the 2D spectrogram features over time (either with mean or max), such that our features are 1D for model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Complete this function below! [1.5 pts]\n",
    "# Note that we'll do train/test splitting below, so you'll call this once per split with the pre-split filenames.\n",
    "# Hint: use tqdm to see progress in a loop - `for audio_file in tqdm(audio_filepaths)` !\n",
    "\n",
    "def get_esc_features(audio_filepaths, feature, sr=16000, aggregation=\"mean\", hop_length=512, win_length=1024):\n",
    "    \"\"\"\n",
    "    Process a list of audio files to extract specified features.\n",
    "    You'll aggregate the features over time, by averaging or taking the max.\n",
    "    \n",
    "    Parameters:\n",
    "    audio_filenames (list of str): List of paths to audio files.\n",
    "    feature (str): Feature type to extract. One of \"lin_spec\", \"log_spec\", \"log_mel_spec\".\n",
    "    sr (int, optional): Target sampling rate for downsampling. Default is 16000.\n",
    "    aggregation (str, optional): Aggregation method over time. Either \"mean\" or \"max\". Default is \"mean\".\n",
    "    hop_length (int, optional): Hop length for feature extraction. Default is 512.\n",
    "    win_length (int, optional): Window length for feature extraction. Default is 1024.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: A NumPy array of shape (n_files, n_features). n_features will differ based on feature type.\n",
    "\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    \n",
    "    for audio_file in tqdm(audio_filepaths):\n",
    "        \n",
    "        # Load and resample audio to sr\n",
    "        \n",
    "        # Extract features depending on 'feature' arg\n",
    "        \n",
    "        # Aggregate over time depending on 'aggregation' arg\n",
    "\n",
    "        pass\n",
    "    \n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Use get_esc_features with the parameters below to get each feature for 10 samples [0.5 pts overall]\n",
    "# TODO : replace this with your data path path\n",
    "data_path = None \n",
    "\n",
    "# TODO : Just demo on 10 files\n",
    "data_chunk = [os.path.join(data_path, f\"audio/{i}\") for i in list(meta_df['filename'])][:10] \n",
    "\n",
    "# params for spec computation\n",
    "resample_sr = 16000\n",
    "agg_type = \"mean\"\n",
    "hop_len = 512\n",
    "win_len = 1024\n",
    "\n",
    "# call your function here\n",
    "lin_spec_ft  = None \n",
    "log_spec_ft  = None\n",
    "log_mel_spec_ft  = None\n",
    "\n",
    "# Test your output shape \n",
    "assert lin_spec_ft.shape == (10,1025) \n",
    "assert log_spec_ft.shape == (10,1025)\n",
    "assert log_mel_spec_ft.shape == (10, 128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì 3. **[QUESTION]** \n",
    "(1) Explain the intuition behind using either 'mean' or 'max' temporal aggregation on a spectrogram. (2) Which do you think would be most effective for sound event classification? [0.2 pts]\n",
    "\n",
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üç¨ Extra Credit (0.5 pts) \n",
    "Add another signal-processing based feature to the function above, and to the tests! This could even be something we haven't talked about a lot in class. Check out Librosa's feature extraction library (https://librosa.org/doc/main/feature.html). There are tons of super interesting spectral features to explore. Write about the feature you chose and why you think it will be helpful for environmental sound classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Splitting [0.5 pts]\n",
    "Next, let's set up our **train/validation/test** splits. Use folds 1-3 for training, 4 for validation, and 5 for testing.\n",
    "\n",
    "Split the data into training and test lists of audio files (`X`) and their corresponding category labels (`y`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : make the train/test split using fold=5 for test. [0.5 pts overall]\n",
    "train = None\n",
    "val = None\n",
    "test = None\n",
    "\n",
    "# TODO : for each split, define a {split}_filepaths and {split}_labels - both should just be lists for now\n",
    "# for forming the list of filepaths, refer to the test cell above \n",
    "train_filepaths = None\n",
    "val_filepaths = None\n",
    "test_filepaths = None\n",
    "\n",
    "train_labels = None\n",
    "val_labels = None\n",
    "test_labels = None\n",
    "\n",
    "# TODO : print the number of classes per split, ensure this is even based on fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model Selection [2.5 pts]\n",
    "Complete the function below, which walks you through a model selection process for training your sound event classification model. You will experiment with using different input features, models, and regularization weighting, with an option to normalize the data or not. For evaluation, you can use scikit-learn's built-in metric functions: https://scikit-learn.org/stable/modules/model_evaluation.html#string-name-scorers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Complete the templated model selection function below [1.5 pts]\n",
    "def train_and_validate(models, features, norm, lambdas, X_train_dict, y_train, X_val_dict, y_val):\n",
    "    \"\"\"\n",
    "    Trains and evaluates models with different hyperparameter combinations on a training and validation set.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : list of str\n",
    "        List of models to evaluate. Options: ['log_reg', 'svm'].\n",
    "    features : list of str\n",
    "        List of feature representations. Options: ['lin_spec', 'log_spec', 'log_mel_spec'].\n",
    "    norm : bool\n",
    "        Whether to apply normalization (True/False).\n",
    "    lambdas : list of float\n",
    "        List of regularization strengths (inverted for `C` parameter).\n",
    "    X_train_dict : dict\n",
    "        Dictionary containing feature datasets for training (keys are feature names, values are corresponding arrays).\n",
    "    y_train : array-like\n",
    "        Training labels.\n",
    "    X_val_dict : dict\n",
    "        Dictionary containing feature datasets for validation (keys are feature names, values are corresponding arrays).\n",
    "    y_val : array-like\n",
    "        Validation labels.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    results : list of dict\n",
    "        A list of dictionaries containing model configurations and their validation accuracies.\n",
    "\n",
    "        Each model configuration should give you a dictionary like so: \n",
    "        \n",
    "        curr_results = { 'model': m,\n",
    "                    'feature': f,\n",
    "                    'normalized': norm,\n",
    "                    'lambda': lam,\n",
    "                    'val_accuracy': accuracy,\n",
    "                    'val_precision': precision,\n",
    "                    'val_recall': recall,\n",
    "                    'val_f1_score': f1 }\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for f in features: \n",
    "        # Retrieve feature matrices\n",
    "        # TODO \n",
    "        \n",
    "        # Min-max scaling, use scikit-learn\n",
    "        if norm:\n",
    "            # TODO \n",
    "            pass\n",
    "        \n",
    "        for m in models:\n",
    "            for lam in lambdas:\n",
    "                print(f'\\nNow training: feature: {f} || model: {m} || lambda: {lam} || norm: {norm}')\n",
    "                \n",
    "                # Model training\n",
    "                # TODO \n",
    "                \n",
    "                # Compute performance metrics\n",
    "                # Use scikit-learn's metric functions\n",
    "                # TODO \n",
    "                accuracy = None\n",
    "                precision = None\n",
    "                recall = None\n",
    "                f1 = None\n",
    "\n",
    "                curr_results = {\n",
    "                    'model': m,\n",
    "                    'feature': f,\n",
    "                    'normalized': norm,\n",
    "                    'lambda': lam,\n",
    "                    'val_accuracy': accuracy,\n",
    "                    'val_precision': precision,\n",
    "                    'val_recall': recall,\n",
    "                    'val_f1_score': f1\n",
    "                }\n",
    "                print(curr_results)\n",
    "                \n",
    "                # Store results\n",
    "                results.append(curr_results)\n",
    "                    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : run this cell to set up your features for your model selection script [0.25 pts]\n",
    "# These features use MEAN pooling over time\n",
    "\n",
    "# TODO : use your get_esc_features function to get the training and validation features\n",
    "resample_sr = 16000\n",
    "agg_type = \"mean\"\n",
    "hop_len = 512\n",
    "win_len = 1024\n",
    "\n",
    "X_train_lin_spec_mean  = None\n",
    "X_train_log_spec_mean  = None\n",
    "X_train_log_mel_spec_mean  = None\n",
    "\n",
    "X_val_lin_spec_mean  = None\n",
    "X_val_log_spec_mean  = None\n",
    "X_val_log_mel_spec_mean  = None\n",
    "\n",
    "\n",
    "# Set up feature dictionaries\n",
    "X_train_dict_mean = {\n",
    "    'lin_spec': X_train_lin_spec_mean,\n",
    "    'log_spec': X_train_log_spec_mean,\n",
    "    'log_mel_spec': X_train_log_mel_mean,\n",
    "}\n",
    "\n",
    "X_val_dict_mean = {\n",
    "    'lin_spec': X_val_lin_spec_mean,\n",
    "    'log_spec': X_val_log_spec_mean,\n",
    "    'log_mel_spec': X_val_log_mel_spec_mean\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : same as above, but use MAX temporal pooling [0.25 pts]\n",
    "# Use your get_esc_features function to get the training and validation features\n",
    "\n",
    "resample_sr = 16000\n",
    "agg_type = \"max\"\n",
    "hop_len = 512\n",
    "win_len = 1024\n",
    "\n",
    "\n",
    "X_train_lin_spec_max  = None\n",
    "X_train_log_spec_max  = None\n",
    "X_train_log_mel_spec_max  = None\n",
    "\n",
    "X_val_lin_spec_max  = None\n",
    "X_val_log_spec_max  = None\n",
    "X_val_log_mel_spec_max  = None\n",
    "\n",
    "\n",
    "# Set up feature dictionaries\n",
    "X_train_dict_max = {\n",
    "    'lin_spec': X_train_lin_spec_max,\n",
    "    'log_spec': X_train_log_spec_max,\n",
    "    'log_mel_spec': X_train_log_mel_max,\n",
    "}\n",
    "\n",
    "X_val_dict_mean = {\n",
    "    'lin_spec': X_val_lin_spec_max,\n",
    "    'log_spec': X_val_log_spec_max,\n",
    "    'log_mel_spec': X_val_log_mel_spec_max\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è‚è±Ô∏è Note that the code below runs a lot of experiments (18)! This may take ~10 minutes to run. To save time, we'll always keep the **data normalized** (also a best practice!). You may experiment with flipping this to False, but note that you may see very long model training times and possible lack of model convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Run this cell, which will run 18 combinations of parameters for model training (wow!) [0.25 pts]\n",
    "# This uses the MEAN pooled features\n",
    "results = train_and_validate(\n",
    "    models=['log_reg', 'svm'],\n",
    "    features=['lin_spec', 'log_spec', 'log_mel_spec'],\n",
    "    norm=True,\n",
    "    lambdas=[0.01, 1, 10],\n",
    "    X_train_dict=X_train_dict_mean,\n",
    "    y_train=train_labels,\n",
    "    X_val_dict=X_val_dict_mean,\n",
    "    y_val=val_labels\n",
    ")\n",
    "\n",
    "# Display results in a nice DataFrame!\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : What about when we use max-pooled features instead of mean? [0.25 pts]\n",
    "# ***IMPORTANT: Choose the top 2 configurations from above and train and validate models using the max-pooled features\n",
    "\n",
    "# TODO : modify this to contain only a subset of experiments (unless you want to run 18 more models!)\n",
    "results_max = train_and_validate(\n",
    "    models=['log_reg', 'svm'], # pick a subset of models to try here\n",
    "    features=['lin_spec', 'log_spec', 'log_mel_spec'], # pick a subset of features to try here\n",
    "    norm=True,\n",
    "    lambdas=[0.01, 1, 10], # pick a subset of lambdas to try here\n",
    "    X_train_dict=X_train_dict_max,\n",
    "    y_train=train_labels,\n",
    "    X_val_dict=X_val_dict_max,\n",
    "    y_val=val_labels\n",
    ")\n",
    "\n",
    "# Display results in a nice DataFrame of the max-pooled results!\n",
    "pd.DataFrame(results_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### üç¨ Extra Credit (0.5 pts) \n",
    "Experiment with a model type besides logistic regression and SVM. Check out scikit-learn documentation for classifiers, and incorporate another one into the model selection function and the training gridsearch experiment above. Report the results and write about why you chose this model and how it performed relative to log reg and SVM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### üç¨ Extra Credit (1 pt) \n",
    "Create another version of the model selection function: `train_and_cross_validate(models, features, norm, lambdas, X_train_dict, y_train)` that does 4-fold cross validation instead of taking a pre-split validation set. Note that this would recquire re-splitting the original data (e.g. use folds 1-4 for training (and internally cross-val), and fold 5 for test. Because this would mean training 4x the models and that would take a long time, instead use the best two model configurations found in the main experiment above to run your cross validation experiments. Report metrics for each of the two experiments and 4-fold trainings, as well as average metrics per experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.5 Evaluation [1 pt]\n",
    "\n",
    "Based on your model selection experiments above, pick the best combination of the hyperparameters:\n",
    "- spectrogram feature (linear spec, log spec, log-mel spec)\n",
    "- mean vs. max pooling of features\n",
    "- model type (logistic regression or SVM)\n",
    "- regularization weight lambda\n",
    "\n",
    "\n",
    "Choose based on **overall accuracy**. When you don't have to worry about class imbalance (fortunate for this dataset), accuracy is a fine metric to use for model selection.\n",
    "Use these parameters to train one final model (**train** dataset), and finally evaluate on your **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : pick your best combination of parameters (including mean or max and train that model, then evaluate on the TEST dataset [1 pt]\n",
    "# Don't forget to continue min-max normalizing!\n",
    "X_test_log_spec = None # Use get_esc_features()  \n",
    "X_test_dict = {}\n",
    "results_test = None # either use the train_and_validate function (but on test data), or explicitly step through the fitting/eval process here\n",
    "\n",
    "# Print your final test results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.6 Analysis [0.4 pts]\n",
    "‚ùì 4. **[QUESTION]** (1) Which combination of parameters did you find the best in terms of overall accuracy? (2) Explain your hypothesis on why this combination works best for environmental sound classification. [0.2 pts]\n",
    "\n",
    "**ANSWER:**\n",
    "\n",
    "‚ùì 5. **[QUESTION]** \n",
    "Above we used overall accuracy to select the best model. (1) Does the trend in overall accuracy follow the trends you see in the other metrics (precision, recall, F1 score). (2) Explain a scenario when you might want to use F1-score instead of accuracy for multi-class classification. [0.2 pts]\n",
    "\n",
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Have you answered all 5 of the written analysis questions throughout the notebook? \n",
    "Yay! You're doing great :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:MLenv] *",
   "language": "python",
   "name": "conda-env-MLenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
